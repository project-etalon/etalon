python -m vllm.entrypoints.openai.api_server \
--model {{ openai_server_model }} \
--dtype auto \
--api-key {{ openai_api_key }} \
-tp {{ tp }} \
-pp {{ pp }} \
--port {{ port }} \
--rope-scaling '{{ rope_scaling }}' \
--max-num-batched-tokens {{ max_num_batched_tokens }} \
--enable-chunked-prefill \
--uvicorn-log-level error \
--disable-log-stats \
--disable-log-requests
