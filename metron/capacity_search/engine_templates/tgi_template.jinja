docker run \
--gpus {{ cuda_devices }} \
--shm-size 64g \
-p {{ port }}:80 \
-v $PWD/data:/data ghcr.io/huggingface/text-generation-inference:2.2.0 \
--model-id {{ openai_server_model }} \
--rope-scaling {{ rope_scaling_type }} \
--rope-factor {{ rope_scaling_factor }}
